{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "##\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "##\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import logging\n",
    "import backtrace\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "sys.path.append(\"../../settler\")\n",
    "from brain.src.lib.postgres import connect as connectDatabase\n",
    "from brain.src.lib.s3 import connect as connectS3\n",
    "from brain.src.lib.postgres import getConnection\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "backtrace.hook()\n",
    "load_dotenv(find_dotenv(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delRowWithOddValue(df, col, num):\n",
    "    \"\"\"Delete rows with a value on `col` with fewer counts than `num`.\"\"\"\n",
    "    freq = items[col].value_counts()\n",
    "    values = freq[freq>num].keys()\n",
    "    return df[df[col].isin(values)]\n",
    "\n",
    "def changeRowWithOddValue(old, col, num, replace):\n",
    "    \"\"\"Change values with fewer counts than `num` to `replace`.\"\"\"\n",
    "    \n",
    "    freq = items[col].value_counts()\n",
    "    values = freq[freq<num].keys()\n",
    "    df = old.copy()\n",
    "    df[col][df[col].isin(values)] = replace\n",
    "    return df\n",
    "\n",
    "def cleanUpOunces(row):\n",
    "    if pd.isnull(row):\n",
    "        return np.nan\n",
    "    if type(row) == float:\n",
    "        return int(row)\n",
    "    row = row.replace('oz.','').replace('oz', '').replace('OZ', '').replace('Z', '').replace('0z', '')\n",
    "    return int(float(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 309130: expected 20 fields, saw 28\\n'\n",
      "<string>:2: DtypeWarning: Columns (4,6,13,14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 715 ms, total: 5.28 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "items = pd.read_csv('../../../Downloads/BlackHawk/AB_2018.csv', error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "items.rename(columns={col:col.lower() for col in items.columns}, inplace=True)\n",
    "\n",
    "# Dropping upc\n",
    "# items.drop(['city', 'upc'], inplace=True, axis=1) # Zip will take care of this\n",
    "items.drop(['date_of_originating_submission'], inplace=True, axis=1)\n",
    "\n",
    "items['state'] = items['state'].astype(str)\n",
    "items['package_type'] = items['package_type'].astype(str)\n",
    "items['product_name'] = items['product_name'].astype(str)\n",
    "items['brand_family'] = items['brand_family'].astype(str)\n",
    "items['purchase_location'] = items['purchase_location'].astype(str)\n",
    "items['brand_name'] = items['brand_name'].astype(str)\n",
    "items['gender'] = items['gender'].astype(str)\n",
    "items['zip'] = items['zip'].astype(str)\n",
    "\n",
    "items['customer_age'] = pd.to_numeric(items['customer_age'], errors='coerce')\n",
    "items['pack_size'] = pd.to_numeric(items['pack_size'], errors='coerce')\n",
    "items['customer_number'] = pd.to_numeric(items['customer_number'], errors='coerce')\n",
    "\n",
    "# Get rid of Canada zipcodes for now\n",
    "items = items[~items.zip.str.contains('[A-Z]',na=False)]\n",
    "items['zip'] = items['zip'].astype(int)\n",
    "items['purchase_price'] = pd.to_numeric(items['purchase_price'], errors='coerce')\n",
    "\n",
    "items.package_type = items.package_type.str.lower()\n",
    "\n",
    "# items.set_index('tracking_number')\n",
    "# shops['id'] = shops['id'].astype(np.int16)\n",
    "\n",
    "# # Drop these NaN columns\n",
    "items.drop(['brand_family', 'gender', 'ab_brand_code'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 368 ms, total: 3.67 s\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# PACK SIZE\n",
    "items = items[~items.pack_size.isnull()]\n",
    "assert items.pack_size.isna().sum() < 50, \"Expected this error to be small\"\n",
    "\n",
    "# OUNCES\n",
    "items = items[~items.ounces.isnull()]\n",
    "items.ounces = items.ounces.apply(cleanUpOunces).astype(np.int)\n",
    "items = delRowWithOddValue(items, 'ounces', 10)\n",
    "items['ounces'] = items['ounces'].astype(int)\n",
    "\n",
    "# def getTotalBottles(row):\n",
    "#     return row\n",
    "# items['total_bottles'] = items.apply(getTotalBottles, axis=1)\n",
    "\n",
    "# STORE\n",
    "items['store'] = items['zip'].map(str) + ':' +\\\n",
    "    items['purchase_location'].map(str) + 'in ' +\\\n",
    "    items['city'].map(str) + ', ' +\\\n",
    "    items['state'].map(str)\n",
    "items = delRowWithOddValue(items, 'store', 100)\n",
    "\n",
    "# PACKAGE\n",
    "# Create joint column to describe product better than product field\n",
    "# Much faster than using df.apply.\n",
    "items['product'] = items['ounces'].map(str) + 'oz ' +\\\n",
    "    items['pack_size'].map(str) + 'pack of ' +\\\n",
    "    items['brand_name'].map(str)\n",
    "items = delRowWithOddValue(items, 'product', 100)\n",
    "\n",
    "# # PRODUCT NAME\n",
    "# items = delRowWithOddValue(items, 'product_name', 100)\n",
    "# items['product_name'] = items['product_name'].astype(str)\n",
    "\n",
    "# UPC\n",
    "items = delRowWithOddValue(items, 'upc', 10)\n",
    "items['upc'] = items['upc'].astype(str)\n",
    "\n",
    "# PACKAGE TYPE\n",
    "items = delRowWithOddValue(items, 'package_type', 30)\n",
    "items['package_type'] = items['package_type'].astype(str)\n",
    "\n",
    "# ZIP\n",
    "items = delRowWithOddValue(items, 'zip', 100)\n",
    "items['zip'] = items['zip'].astype(str)\n",
    "\n",
    "# LOCATION\n",
    "items = changeRowWithOddValue(items, 'purchase_location', 10, np.nan)\n",
    "items['purchase_location'] = items['purchase_location'].astype(str)\n",
    "\n",
    "# OTHERS\n",
    "items = items[~items.purchase_date.isnull()]\n",
    "items = items[items.product_name!='Invalid UPC Product']\n",
    "\n",
    "items = items[items.purchase_price<60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize product names\n",
    "# display(items.product_name.value_counts())\n",
    "# names = items.product_name.value_counts().keys()\n",
    "# vai = set(map(lambda x: x.lower().replace('12pk','12 pack').replace('-',' '), names))\n",
    "# print(len(vai))\n",
    "# vai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items['brand_name'].value_counts().plot(kind='bar',figsize=(20,10))\n",
    "# items.groupby('brand_name').size().value_counts().plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 72.1 ms, total: 1.3 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Categorize stuff\n",
    "\n",
    "# https://stackoverflow.com/questions/42196589\n",
    "\n",
    "final = items.rename(columns={\n",
    "    'purchase_date': 'date',\n",
    "})\n",
    "\n",
    "final.to_csv('../../../Downloads/BlackHawk/FELIPE_AB_2018_CLEAN.csv',\n",
    "             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to understand what the tracking_number is.\n",
    "\n",
    "# # a = pricy.groupby(['tracking_number']).agg({'product_name_':'nunique'})\n",
    "# a.reset_index(inplace=True)\n",
    "# a[a.product_name_>1]\n",
    "\n",
    "# items[items.tracking_number==839607498]\n",
    "\n",
    "# a = items[~items._brand_name.isna()].groupby(['tracking_number']).agg({'_product_name':'nunique'})\n",
    "\n",
    "\n",
    "# Relationship between product (col which we created) and upc is 1-*\n",
    "# items.drop_duplicates(['upc','product'])[['upc','product']].sort_values('product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.4 s, sys: 200 ms, total: 9.6 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.read_csv('../../../Downloads/BlackHawk/FELIPE_AB_2018_CLEAN.csv')\n",
    "train['date'] = pd.to_datetime(train['date']) # .astype('datetime64[ns]')\n",
    "\n",
    "train = train[train['date'].between('2017-01-01','2019-01-01')]\n",
    "\n",
    "train['purchase_price'] = train['purchase_price'].astype('float64')\n",
    "train['ounces'] = train['ounces'].astype(int)\n",
    "train['zip'] = train['zip'].astype(str)\n",
    "\n",
    "\n",
    "toEncode = [\n",
    "    'city',\n",
    "    'state',\n",
    "    'package_type',\n",
    "    'purchase_location',\n",
    "    'product_name',\n",
    "    'brand_name',\n",
    "    'store',\n",
    "    'product',\n",
    "]\n",
    "for col in toEncode:\n",
    "    # items[col].value_counts().plot(kind='bar',figsize=(20,10))\n",
    "    le = LabelEncoder()\n",
    "    train['__%s' % col] = train[col]\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    train[col] = train[col].astype(int)\n",
    "    # def translatePackage(list):\n",
    "    #     return dict(zip(list, le.inverse_transform(list)))\n",
    "\n",
    "_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 10.5 ms, total: 130 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train.sort_values(['date','product_name'], inplace=True)\n",
    "\n",
    "train = _train.copy()\n",
    "\n",
    "# train.drop('purchase_location', axis=1)\n",
    "\n",
    "# We are ignoring train.location for now!\n",
    "zips = pd.DataFrame({'id':train.zip.unique()})\n",
    "# products = pd.DataFrame({'id':train['brand'].unique()})\n",
    "\n",
    "# train['product'] = train['brand']\n",
    "\n",
    "products = train[[\n",
    "    'brand_name',\n",
    "    'ounces',\n",
    "    'pack_size',\n",
    "#     'package_type', # Not unique per prod!\n",
    "#     'upc', # Not unique per prod, which is weird.\n",
    "    'product', # Id\n",
    "#     '__product_name',\n",
    "    '__brand_name',\n",
    "    '__product',\n",
    "]].drop_duplicates('product')\n",
    "products.rename(columns={'product':'id'}, inplace=True)\n",
    "\n",
    "\n",
    "shops = train[[\n",
    "    'city',\n",
    "    'state',\n",
    "    'zip',\n",
    "    'purchase_location',\n",
    "    'store', # Id\n",
    "    '__city',\n",
    "    '__state',\n",
    "    '__purchase_location',\n",
    "    '__store',\n",
    "]].drop_duplicates('store')\n",
    "products.rename(columns={'store':'id'}, inplace=True)\n",
    "\n",
    "sales = train.drop([\n",
    "    'brand_name',\n",
    "    'ounces',\n",
    "    'pack_size',\n",
    "    '__brand_name',\n",
    "    '__product',\n",
    "    #\n",
    "    'city',\n",
    "    'state',\n",
    "    'zip',\n",
    "    'purchase_location',\n",
    "    '__city',\n",
    "    '__state',\n",
    "    '__purchase_location',\n",
    "    '__store',\n",
    "], axis=1)\n",
    "\n",
    "train['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'Products.id', 'shop': 'Shops.id', '__DATE__': '__DATE__'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dev/assembler/src/index.py\u001b[0m in \u001b[0;36mprocessShape\u001b[0;34m(shape, dataframes)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m   \u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Matrix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenOutputMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Matrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CMONTH(date)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/assembler/src/index.py\u001b[0m in \u001b[0;36mgenOutputMatrix\u001b[0;34m(dataframes, shape)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mcolUniqueVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0mcolUniqueVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeyIn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;31m# colUniqueVals['product'] = df[keyIn].unique()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json5\n",
    "import pprint\n",
    "import builtins\n",
    "from src import processShape\n",
    "\n",
    "# To save memory for now??\n",
    "# sales = train.copy() # .iloc[-100000:]\n",
    "\n",
    "sales['id'] = sales.index\n",
    "\n",
    "# tracking_number for same order\n",
    "\n",
    "def getAssemblerShape():\n",
    "    json = open('featuresbev.json5').read()\n",
    "    obj = json5.loads(json)\n",
    "    features = []\n",
    "    for f in obj['features']:\n",
    "        features.append(f.strip().replace('tblock', 'month_block')\n",
    "                        .replace('tcount', 'item_cnt_month'))\n",
    "    obj['features'] = features\n",
    "    return obj\n",
    "\n",
    "shape = getAssemblerShape()\n",
    "\n",
    "processShape(shape, {\n",
    "    \"Sales\": sales,\n",
    "    \"Shops\": shops,\n",
    "    \"Products\": products,\n",
    "})\n",
    "\n",
    "# pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
