{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize product names\n",
    "# display(items.product_name.value_counts())\n",
    "# names = items.product_name.value_counts().keys()\n",
    "# vai = set(map(lambda x: x.lower().replace('12pk','12 pack').replace('-',' '), names))\n",
    "# print(len(vai))\n",
    "# vai\n",
    "# from difflib import SequenceMatcher\n",
    "# def similar(a, b):\n",
    "#     return SequenceMatcher(None, a, b).ratio()\n",
    "# testing = items.copy()\\\n",
    "#     [['customer_age', 'customer_number']]\n",
    "# testing = testing[~testing.customer_number.isna()]\n",
    "# for age in testing.customer_age.unique():\n",
    "#     thatage = testing[items.customer_age==age]\n",
    "#     for i, row in thatage.iterrows():\n",
    "#         c1 = '%d' % row['customer_number']\n",
    "#         for i2, row2 in thatage.iterrows():\n",
    "#             c2 = '%d' % row2['customer_number']\n",
    "#             if i == i2 or c1 == c2:\n",
    "#                 continue\n",
    "#             if similar(c1, c2)>0.9:\n",
    "#                 print(\"!!\", c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "##\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "##\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import logging\n",
    "import backtrace\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "sys.path.append(\"../../settler\")\n",
    "from brain.src.lib.postgres import connect as connectDatabase\n",
    "from brain.src.lib.s3 import connect as connectS3\n",
    "from brain.src.lib.postgres import getConnection\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "backtrace.hook()\n",
    "load_dotenv(find_dotenv(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delRowWithOddValue(df, col, num):\n",
    "    \"\"\"Delete rows with a value on `col` with fewer counts than `num`.\"\"\"\n",
    "    freq = items[col].value_counts()\n",
    "    values = freq[freq>num].keys()\n",
    "    print(\"Deleting %s infrequent values for col %s\" % \\\n",
    "         (df.shape[0]-df[col].isin(values).sum(), col))\n",
    "    return df[df[col].isin(values)]\n",
    "\n",
    "def changeRowWithOddValue(old, col, num, replace):\n",
    "    \"\"\"Change values with fewer counts than `num` to `replace`.\"\"\"\n",
    "    \n",
    "    freq = items[col].value_counts()\n",
    "    values = freq[freq<num].keys()\n",
    "    df = old.copy()\n",
    "    df[col][df[col].isin(values)] = replace\n",
    "    return df\n",
    "\n",
    "def cleanUpOunces(row):\n",
    "    if pd.isnull(row):\n",
    "        return np.nan\n",
    "    if type(row) == float:\n",
    "        return int(row)\n",
    "    row = row.replace('oz.','').replace('oz', '').replace('OZ', '').replace('Z', '').replace('0z', '')\n",
    "    return int(float(row))\n",
    "\n",
    "def plotValueCounts(col):\n",
    "    items[col].value_counts().plot(kind='bar',figsize=(20,10))\n",
    "\n",
    "def plotValueFreqCounts(col):\n",
    "    items.groupby(col).size().value_counts().plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 309130: expected 20 fields, saw 28\\n'\n",
      "<string>:2: DtypeWarning: Columns (4,6,13,14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 812 ms, total: 6.39 s\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "items = pd.read_csv('../../../Downloads/BlackHawk/AB_2018.csv', error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "items.rename(columns={col:col.lower() for col in items.columns}, inplace=True)\n",
    "\n",
    "# Dropping upc\n",
    "# items.drop(['city', 'upc'], inplace=True, axis=1) # Zip will take care of this\n",
    "items.drop(['date_of_originating_submission'], inplace=True, axis=1)\n",
    "\n",
    "items['state'] = items['state'].astype(str)\n",
    "items['package_type'] = items['package_type'].astype(str)\n",
    "items['product_name'] = items['product_name'].astype(str)\n",
    "items['brand_family'] = items['brand_family'].astype(str)\n",
    "items['purchase_location'] = items['purchase_location'].astype(str)\n",
    "items['brand_name'] = items['brand_name'].astype(str)\n",
    "items['gender'] = items['gender'].astype(str)\n",
    "items['zip'] = items['zip'].astype(str)\n",
    "\n",
    "items['customer_age'] = pd.to_numeric(items['customer_age'], errors='coerce')\n",
    "items['pack_size'] = pd.to_numeric(items['pack_size'], errors='coerce')\n",
    "items['customer_number'] = pd.to_numeric(items['customer_number'], errors='coerce')\n",
    "\n",
    "# Get rid of Canada zipcodes for now\n",
    "items = items[~items.zip.str.contains('[A-Z]',na=False)]\n",
    "items['zip'] = items['zip'].astype(int)\n",
    "items['purchase_price'] = pd.to_numeric(items['purchase_price'], errors='coerce')\n",
    "\n",
    "items.package_type = items.package_type.str.lower()\n",
    "\n",
    "# items.set_index('tracking_number')\n",
    "# shops['id'] = shops['id'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 46 infrequent values for col ounces\n",
      "Deleting 706 infrequent values for col product\n",
      "Deleting 902 infrequent values for col upc\n",
      "Deleting 1 infrequent values for col package_type\n",
      "Deleting 79329 infrequent values for col zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 703 ms, total: 7.1 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Drop empty columns\n",
    "items.drop(['brand_family', 'gender', 'ab_brand_code'], inplace=True, axis=1)\n",
    "\n",
    "# PACK SIZE\n",
    "items = items[~items.pack_size.isnull()]\n",
    "assert items.pack_size.isna().sum() < 50, \"Expected this error to be small\"\n",
    "\n",
    "# OUNCES\n",
    "items = items[~items.ounces.isnull()]\n",
    "items.ounces = items.ounces.apply(cleanUpOunces).astype(np.int)\n",
    "items = delRowWithOddValue(items, 'ounces', 10)\n",
    "items['ounces'] = items['ounces'].astype(int)\n",
    "\n",
    "# def getTotalBottles(row):\n",
    "#     return row\n",
    "# items['total_bottles'] = items.apply(getTotalBottles, axis=1)\n",
    "\n",
    "# STORE\n",
    "items['store'] = items['zip'].map(str) + ':' +\\\n",
    "    items['purchase_location'].map(str) + 'in ' +\\\n",
    "    items['city'].map(str) + ', ' +\\\n",
    "    items['state'].map(str)\n",
    "# items = delRowWithOddValue(items, 'store', 5)\n",
    "\n",
    "# PACKAGE\n",
    "# Create joint column to describe product better than product field\n",
    "# Much faster than using df.apply.\n",
    "items['product'] = items['ounces'].map(str) + 'oz ' +\\\n",
    "    items['pack_size'].map(str) + 'pack of ' +\\\n",
    "    items['brand_name'].map(str)\n",
    "items = delRowWithOddValue(items, 'product', 10)\n",
    "\n",
    "# # PRODUCT NAME\n",
    "# items = delRowWithOddValue(items, 'product_name', 100)\n",
    "# items['product_name'] = items['product_name'].astype(str)\n",
    "\n",
    "# UPC\n",
    "items = delRowWithOddValue(items, 'upc', 10)\n",
    "items['upc'] = items['upc'].astype(str)\n",
    "\n",
    "# PACKAGE TYPE\n",
    "items = delRowWithOddValue(items, 'package_type', 30)\n",
    "items['package_type'] = items['package_type'].astype(str)\n",
    "\n",
    "# ZIP\n",
    "items = delRowWithOddValue(items, 'zip', 30)\n",
    "items['zip'] = items['zip'].astype(str)\n",
    "\n",
    "# LOCATION\n",
    "items = changeRowWithOddValue(items, 'purchase_location', 10, np.nan)\n",
    "items['purchase_location'] = items['purchase_location'].astype(str)\n",
    "\n",
    "# OTHERS\n",
    "items = items[~items.purchase_date.isnull()]\n",
    "items = items[items.product_name!='Invalid UPC Product']\n",
    "\n",
    "items = items[items.purchase_price<60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1238, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 11, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\", line 1745, in to_csv\n",
      "    formatter.save()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/formats/csvs.py\", line 151, in save\n",
      "    self._save()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/formats/csvs.py\", line 263, in _save\n",
      "    self._save_chunk(start_i, end_i)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/formats/csvs.py\", line 290, in _save_chunk\n",
      "    self.cols, self.writer)\n",
      "  File \"pandas/_libs/writers.pyx\", line 81, in pandas._libs.writers.write_csv_rows\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Categorize stuff\n",
    "\n",
    "# https://stackoverflow.com/questions/42196589\n",
    "\n",
    "final = items.rename(columns={\n",
    "    'purchase_date': 'date',\n",
    "})\n",
    "\n",
    "final.to_csv('../../../Downloads/BlackHawk/FELIPE_AB_2018_CLEAN.csv',\n",
    "             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to understand what the tracking_number is.\n",
    "\n",
    "# # a = pricy.groupby(['tracking_number']).agg({'product_name_':'nunique'})\n",
    "# a.reset_index(inplace=True)\n",
    "# a[a.product_name_>1]\n",
    "\n",
    "# items[items.tracking_number==839607498]\n",
    "\n",
    "# a = items[~items._brand_name.isna()].groupby(['tracking_number']).agg({'_product_name':'nunique'})\n",
    "\n",
    "# Relationship between product (col which we created) and upc is 1-*\n",
    "# items.drop_duplicates(['upc','product'])[['upc','product']].sort_values('product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# only used in _encode below, see docstring there for details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.read_csv('../../../Downloads/BlackHawk/FELIPE_AB_2018_CLEAN.csv')\n",
    "train['date'] = pd.to_datetime(train['date']) # .astype('datetime64[ns]')\n",
    "\n",
    "train = train[train['date'].between('2017-01-01','2019-01-01')]\n",
    "\n",
    "train['purchase_price'] = train['purchase_price'].astype('float64')\n",
    "train['ounces'] = train['ounces'].astype(int)\n",
    "train['zip'] = train['zip'].astype(str)\n",
    "\n",
    "\n",
    "toEncode = [\n",
    "    'city',\n",
    "    'state',\n",
    "    'package_type',\n",
    "    'purchase_location',\n",
    "    'product_name',\n",
    "    'brand_name',\n",
    "    'store',\n",
    "    'product',\n",
    "]\n",
    "for col in toEncode:\n",
    "    # items[col].value_counts().plot(kind='bar',figsize=(20,10))\n",
    "    le = LabelEncoder()\n",
    "    train['__%s' % col] = train[col]\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    train[col] = train[col].astype(int)\n",
    "    # def translatePackage(list):\n",
    "    #     return dict(zip(list, le.inverse_transform(list)))\n",
    "\n",
    "_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# train.sort_values(['date','product_name'], inplace=True)\n",
    "train = _train.copy()\n",
    "\n",
    "products = train[[\n",
    "    'brand_name',\n",
    "    'ounces',\n",
    "    'pack_size',\n",
    "#     'package_type', # Not unique per prod!\n",
    "#     'upc', # Not unique per prod, which is weird.\n",
    "    'product', # Id\n",
    "    '__brand_name',\n",
    "    '__product',\n",
    "]].drop_duplicates('product')\n",
    "products.rename(columns={'product':'id'}, inplace=True)\n",
    "# products.set_index('id')\n",
    "\n",
    "shops = train[[\n",
    "    'city',\n",
    "    'state',\n",
    "    'zip',\n",
    "    'purchase_location',\n",
    "    'store', # Id\n",
    "    '__city',\n",
    "    '__state',\n",
    "    '__purchase_location',\n",
    "    '__store',\n",
    "]].drop_duplicates('store')\n",
    "shops.rename(columns={'store':'id'}, inplace=True)\n",
    "# shops.set_index('id')\n",
    "\n",
    "sales = train.drop([\n",
    "#     'brand_name',\n",
    "    'ounces',\n",
    "#     'pack_size',\n",
    "#     '__brand_name',\n",
    "    '__product',\n",
    "    #\n",
    "#     'city',\n",
    "    'state',\n",
    "#     'zip',\n",
    "    'purchase_location',\n",
    "#     '__city',\n",
    "    '__state',\n",
    "    '__purchase_location',\n",
    "    '__store',\n",
    "], axis=1)\n",
    "sales.rename(columns={'store':'shop'}, inplace=True)\n",
    "\n",
    "sales['id'] = sales.index\n",
    "sales['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for debugging\n",
    "def setMonthBlock(row):\n",
    "    parsed = row['date']\n",
    "    return (parsed.year - 2000)*12+parsed.month\n",
    "\n",
    "sales['month_block'] = sales.apply(setMonthBlock, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json5\n",
    "import pprint\n",
    "import builtins\n",
    "from src import processShape\n",
    "\n",
    "# To save memory for now??\n",
    "# sales = train.copy() # .iloc[-100000:]\n",
    "\n",
    "def getAssemblerShape():\n",
    "    json = open('featuresbev.json5').read()\n",
    "    obj = json5.loads(json)\n",
    "    features = []\n",
    "    for f in obj['features']:\n",
    "        features.append(f.strip().replace('tblock', 'month_block')\n",
    "                        .replace('tcount', 'item_cnt_month'))\n",
    "    obj['features'] = features\n",
    "    return obj\n",
    "\n",
    "shape = getAssemblerShape()\n",
    "\n",
    "processShape(shape, {\n",
    "    \"Sales\": sales,\n",
    "    \"Shops\": shops,\n",
    "    \"Products\": products,\n",
    "})\n",
    "\n",
    "# pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
